{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64fbe3c5-c4d0-4a74-ac68-490358a5d295",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg is installed! Using ffmpeg for audio processing.\n",
      "M1/M2 Mac detected - ensuring PyTorch with MPS support is installed...\n",
      "Using CPU mode for all models to ensure compatibility on Apple Silicon\n",
      "PyTorch version: 2.6.0\n",
      "Using faster-whisper for improved performance on CPU!\n",
      "Loaded faster-whisper model with optimized CPU settings\n",
      "Loading summarization model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarization model loaded!\n",
      "\n",
      "Checking for audio processing tools...\n",
      "âœ… Found ffmpeg for audio processing.\n",
      "\n",
      "tarting Voice-to-Text Application...\n",
      "Running on arm with CPU acceleration\n",
      "Loading models (this may take a moment)...\n",
      "Once loaded, the application will be available at http://127.0.0.1:7860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import time\n",
    "import os\n",
    "import tempfile\n",
    "import subprocess\n",
    "import sys\n",
    "import platform\n",
    "\n",
    "# Check for audio processing tools\n",
    "def check_audio_tools():\n",
    "    # Try to find ffmpeg first (most common)\n",
    "    try:\n",
    "        subprocess.run(['ffmpeg', '-version'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        print(\"ffmpeg is installed! Using ffmpeg for audio processing.\")\n",
    "        return \"ffmpeg\"\n",
    "    except FileNotFoundError:\n",
    "        # Try libav (avconv) as an alternative\n",
    "        try:\n",
    "            subprocess.run(['avconv', '-version'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            print(\"avconv (libav) is installed! Using libav for audio processing.\")\n",
    "            return \"libav\"\n",
    "        except FileNotFoundError:\n",
    "            # Try SoX as another alternative\n",
    "            try:\n",
    "                subprocess.run(['sox', '--version'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "                print(\"SoX is installed! Using SoX for audio processing.\")\n",
    "                return \"sox\"\n",
    "            except FileNotFoundError:\n",
    "                print(\"No audio processing tools found. Please install one of the following:\")\n",
    "                print(\"- ffmpeg (recommended): brew install ffmpeg\")\n",
    "                print(\"- libav: brew install libav\")\n",
    "                print(\"- SoX: brew install sox\")\n",
    "                print(\"\\nWould you like to continue without audio tools? Some functionality may be limited.\")\n",
    "                response = input(\"Continue anyway? (y/n): \")\n",
    "                if response.lower() != 'y':\n",
    "                    sys.exit(1)\n",
    "                return \"none\"\n",
    "\n",
    "# Check for required packages and install if missing\n",
    "def check_and_install_packages():\n",
    "    required_packages = ['whisper', 'transformers', 'torch', 'sentencepiece', 'accelerate']\n",
    "    \n",
    "    # For M1 Macs, ensure PyTorch is installed with MPS support\n",
    "    if platform.processor() == 'arm' and sys.platform == 'darwin':\n",
    "        print(\"M1/M2 Mac detected - ensuring PyTorch with MPS support is installed...\")\n",
    "        try:\n",
    "            import torch\n",
    "            if not torch.backends.mps.is_available():\n",
    "                print(\"PyTorch MPS is not available. Installing PyTorch with MPS support...\")\n",
    "                subprocess.run([sys.executable, '-m', 'pip', 'install', '--upgrade', 'torch'])\n",
    "        except (ImportError, AttributeError):\n",
    "            print(\"Installing PyTorch with MPS support...\")\n",
    "            subprocess.run([sys.executable, '-m', 'pip', 'install', '--upgrade', 'torch'])\n",
    "    \n",
    "    for package in required_packages:\n",
    "        try:\n",
    "            __import__(package)\n",
    "        except ImportError:\n",
    "            print(f\"{package} not found. Installing...\")\n",
    "            if package == 'torch' and platform.processor() == 'arm' and sys.platform == 'darwin':\n",
    "                # Skip if we already handled torch for M1\n",
    "                continue\n",
    "            subprocess.run([sys.executable, '-m', 'pip', 'install', package])\n",
    "\n",
    "# Run checks\n",
    "audio_tool = check_audio_tools()\n",
    "check_and_install_packages()\n",
    "\n",
    "# Now import after checks\n",
    "import torch\n",
    "import whisper\n",
    "from transformers import pipeline\n",
    "\n",
    "# Force CPU-only mode to avoid MPS sparse tensor issues\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"  # Enable MPS fallback for operations that support it\n",
    "device = \"cpu\"  # Force CPU for all models\n",
    "print(\"Using CPU mode for all models to ensure compatibility on Apple Silicon\")\n",
    "\n",
    "# Check for PyTorch installation\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"PyTorch version: {torch.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"PyTorch not found. Installing...\")\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'torch'])\n",
    "\n",
    "\n",
    "# Try to use faster-whisper which works better on M1 Macs with CPU\n",
    "try:\n",
    "    from faster_whisper import WhisperModel\n",
    "    print(\"Using faster-whisper for improved performance on CPU!\")\n",
    "    \n",
    "    # Always use CPU with int8 quantization (most reliable on M1)\n",
    "    model = WhisperModel(\"small\", device=\"cpu\", compute_type=\"int8\", cpu_threads=4)\n",
    "    use_faster_whisper = True\n",
    "    print(\"Loaded faster-whisper model with optimized CPU settings\")\n",
    "        \n",
    "except (ImportError, ValueError) as e:\n",
    "    if isinstance(e, ValueError):\n",
    "        try:\n",
    "            # If int8 failed, try with standard float32\n",
    "            print(f\"Could not use int8 precision: {str(e)}\")\n",
    "            print(\"Trying with standard float32...\")\n",
    "            model = WhisperModel(\"small\", device=\"cpu\", compute_type=\"float32\")\n",
    "            use_faster_whisper = True\n",
    "            print(\"Loaded faster-whisper model with float32 precision\")\n",
    "        except Exception as e2:\n",
    "            print(f\"Failed to initialize faster-whisper: {str(e2)}\")\n",
    "            use_faster_whisper = False\n",
    "    else:\n",
    "        print(\"faster-whisper not found. Using standard whisper.\")\n",
    "        print(\"For better performance on M1/M2 Mac, consider:\")\n",
    "        print(\"pip install faster-whisper\")\n",
    "        use_faster_whisper = False\n",
    "\n",
    "# Load standard whisper as fallback\n",
    "if not use_faster_whisper:\n",
    "    try:\n",
    "        # Ensure we use tiny model which has fewer parameters and is less likely \n",
    "        # to hit compatibility issues\n",
    "        print(\"Loading Whisper tiny model on CPU...\")\n",
    "        model = whisper.load_model(\"tiny\", device=\"cpu\")\n",
    "        print(\"Whisper tiny model loaded successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading standard whisper model: {str(e)}\")\n",
    "        print(\"Trying with environment variable workarounds...\")\n",
    "        # Last resort - use environment variables and minimal model\n",
    "        os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "        model = whisper.load_model(\"tiny\", device=\"cpu\", download_root=os.path.expanduser(\"~/.cache/whisper\"))\n",
    "        print(\"Whisper tiny model loaded with fallback configuration!\")\n",
    "\n",
    "# Load a lightweight summarization model\n",
    "print(\"Loading summarization model...\")\n",
    "try:\n",
    "    # Use a smaller model for better compatibility\n",
    "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device=-1)\n",
    "    print(\"Summarization model loaded!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading standard summarization model: {str(e)}\")\n",
    "    print(\"Trying with a smaller model...\")\n",
    "    try:\n",
    "        # If the large model fails, try with a smaller one\n",
    "        summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-6-6\", device=-1)\n",
    "        print(\"Smaller summarization model loaded as fallback!\")\n",
    "    except Exception as e2:\n",
    "        print(f\"Error loading fallback summarization model: {str(e2)}\")\n",
    "        # Define a simple function that just returns the input as a last resort\n",
    "        def dummy_summarize(text, **kwargs):\n",
    "            words = text.split()\n",
    "            if len(words) > 50:\n",
    "                return [{'summary_text': ' '.join(words[:50]) + '...'}]\n",
    "            return [{'summary_text': text}]\n",
    "        \n",
    "        summarizer = dummy_summarize\n",
    "        print(\"Using basic text truncation as summarization fallback!\")\n",
    "\n",
    "def transcribe_and_summarize(audio_file):\n",
    "    start_time = time.time()\n",
    "    global model  # Use global instead of nonlocal\n",
    "    \n",
    "    # Step 1: Check if audio file was uploaded\n",
    "    if audio_file is None:\n",
    "        return \"Please upload an audio file.\", \"\", 0\n",
    "    \n",
    "    # Step 2: Convert audio if necessary based on the available tool\n",
    "    processed_audio = audio_file\n",
    "    if audio_tool != \"none\" and audio_tool != \"ffmpeg\":\n",
    "        try:\n",
    "            # Create temp file for processed audio\n",
    "            temp_dir = tempfile.gettempdir()\n",
    "            processed_audio = os.path.join(temp_dir, \"processed_audio.wav\")\n",
    "            \n",
    "            if audio_tool == \"libav\":\n",
    "                # Use avconv (libav) to convert\n",
    "                subprocess.run(['avconv', '-i', audio_file, '-ar', '16000', '-ac', '1', processed_audio], \n",
    "                               stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            elif audio_tool == \"sox\":\n",
    "                # Use SoX to convert\n",
    "                subprocess.run(['sox', audio_file, '-r', '16000', '-c', '1', processed_audio], \n",
    "                               stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            \n",
    "            print(f\"Audio processed with {audio_tool}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not process audio with {audio_tool}: {e}\")\n",
    "            # Fall back to original file\n",
    "            processed_audio = audio_file\n",
    "    \n",
    "    # Step 3: Transcribe the audio using Whisper with error handling\n",
    "    transcribe_start = time.time()\n",
    "    try:\n",
    "        if use_faster_whisper:\n",
    "            # Using faster-whisper\n",
    "            segments, info = model.transcribe(processed_audio, beam_size=5)\n",
    "            transcript = \" \".join([segment.text for segment in segments])\n",
    "        else:\n",
    "            # Using standard whisper with additional error handling\n",
    "            try:\n",
    "                result = model.transcribe(processed_audio)\n",
    "                transcript = result[\"text\"]\n",
    "            except RuntimeError as e:\n",
    "                if \"cuda\" in str(e).lower() or \"mps\" in str(e).lower():\n",
    "                    print(\"GPU error detected. Forcing CPU mode and retrying...\")\n",
    "                    # Force CPU mode if GPU fails\n",
    "                    os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "                    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "                    # Reload model on CPU if needed\n",
    "                    model = whisper.load_model(\"tiny\", device=\"cpu\")\n",
    "                    result = model.transcribe(processed_audio)\n",
    "                    transcript = result[\"text\"]\n",
    "                else:\n",
    "                    raise\n",
    "        \n",
    "        if not transcript.strip():\n",
    "            return \"No speech detected in the audio file.\", \"\", 0\n",
    "            \n",
    "        transcribe_time = time.time() - transcribe_start\n",
    "        print(f\"Transcription completed in {transcribe_time:.2f} seconds\")\n",
    "    except Exception as e:\n",
    "        return f\"Error transcribing audio: {str(e)}\", \"\", 0\n",
    "        \n",
    "    # Clean up temp file if created\n",
    "    if processed_audio != audio_file and os.path.exists(processed_audio):\n",
    "        try:\n",
    "            os.remove(processed_audio)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Step 3: Summarize the transcript\n",
    "    summarize_start = time.time()\n",
    "    \n",
    "    # Function to chunk text for summarization\n",
    "    def chunk_text(text, max_length=1000):\n",
    "        words = text.split()\n",
    "        chunks = []\n",
    "        current_chunk = []\n",
    "        \n",
    "        for word in words:\n",
    "            current_chunk.append(word)\n",
    "            if len(\" \".join(current_chunk)) > max_length:\n",
    "                chunks.append(\" \".join(current_chunk))\n",
    "                current_chunk = []\n",
    "        \n",
    "        if current_chunk:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "        \n",
    "        return chunks\n",
    "    \n",
    "    # Process chunks and summarize\n",
    "    chunks = chunk_text(transcript)\n",
    "    chunk_summaries = []\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        # Skip empty chunks\n",
    "        if not chunk.strip():\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # Summarize the chunk\n",
    "            summary = summarizer(chunk, max_length=100, min_length=30, do_sample=False)\n",
    "            chunk_summaries.append(summary[0]['summary_text'])\n",
    "        except Exception as e:\n",
    "            print(f\"Error summarizing chunk: {str(e)}\")\n",
    "            # If summarization fails, include original chunk\n",
    "            chunk_summaries.append(chunk[:100] + \"...\")\n",
    "    \n",
    "    # Combine chunk summaries\n",
    "    summary = \" \".join(chunk_summaries)\n",
    "    \n",
    "    # If we have multiple chunks, summarize again for coherence\n",
    "    if len(chunk_summaries) > 1:\n",
    "        try:\n",
    "            final_summary = summarizer(\" \".join(chunk_summaries), max_length=100, min_length=30, do_sample=False)\n",
    "            summary = final_summary[0]['summary_text']\n",
    "        except Exception as e:\n",
    "            print(f\"Error in final summarization: {str(e)}\")\n",
    "            # Keep existing summary if final summarization fails\n",
    "        \n",
    "    summarize_time = time.time() - summarize_start\n",
    "    \n",
    "    # Calculate total processing time\n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    return transcript, summary, round(total_time, 2)\n",
    "\n",
    "# Create Gradio interface\n",
    "with gr.Blocks(title=\"Audio Transcription & Summarization\") as demo:\n",
    "    gr.Markdown(\"# Audio Transcription & Summarization Tool\")\n",
    "    gr.Markdown(\"Upload an audio file to transcribe and summarize its content.\")\n",
    "    \n",
    "    # Add device and audio tool info\n",
    "    if use_faster_whisper:\n",
    "        gr.Markdown(f\"**Running on:** {platform.processor()} with faster-whisper on CPU\")\n",
    "    else:\n",
    "        gr.Markdown(f\"**Running on:** {platform.processor()} using standard whisper on CPU\")\n",
    "    gr.Markdown(f\"**Audio processing:** Using {audio_tool}\")\n",
    "    \n",
    "    # Add error message display\n",
    "    error_output = gr.Textbox(label=\"Status\", visible=True)\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            # Changed to allow both microphone recording and file upload\n",
    "            audio_input = gr.Audio(sources=[\"microphone\", \"upload\"], type=\"filepath\", label=\"Record or Upload Audio\")\n",
    "            submit_btn = gr.Button(\"Transcribe & Summarize\", variant=\"primary\")\n",
    "            processing_time = gr.Number(label=\"Processing Time (seconds)\", precision=2)\n",
    "        \n",
    "        with gr.Column():\n",
    "            transcript_output = gr.Textbox(label=\"Transcript\", lines=10)\n",
    "            summary_output = gr.Textbox(label=\"Summary\", lines=5)\n",
    "    \n",
    "    # Function to handle errors\n",
    "    def process_with_error_handling(audio_file):\n",
    "        try:\n",
    "            transcript, summary, time_taken = transcribe_and_summarize(audio_file)\n",
    "            return \"\", transcript, summary, time_taken\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error: {str(e)}\"\n",
    "            if \"ffmpeg\" in str(e).lower() or \"audio\" in str(e).lower():\n",
    "                error_msg += \"\\n\\nPlease install an audio processing tool:\\n\"\n",
    "                error_msg += \"- ffmpeg: brew install ffmpeg\\n\"\n",
    "                error_msg += \"- libav: brew install libav\\n\" \n",
    "                error_msg += \"- SoX: brew install sox\"\n",
    "            return error_msg, \"\", \"\", 0\n",
    "    \n",
    "    submit_btn.click(\n",
    "        fn=process_with_error_handling,\n",
    "        inputs=audio_input,\n",
    "        outputs=[error_output, transcript_output, summary_output, processing_time]\n",
    "    )\n",
    "    \n",
    "    gr.Markdown(\"### How to Use\")\n",
    "    gr.Markdown(\"\"\"\n",
    "    1. Upload an audio file (mp3, wav, m4a, etc.)\n",
    "    2. Click the 'Transcribe & Summarize' button\n",
    "    3. Wait for processing (time depends on audio length)\n",
    "    4. View the transcript and summary\n",
    "    \n",
    "    This app uses OpenAI's Whisper (small model) for transcription and BART-large-CNN for summarization.\n",
    "    \"\"\")\n",
    "\n",
    "# Setup function\n",
    "def setup():\n",
    "    \"\"\"Install necessary dependencies before launching the app\"\"\"\n",
    "    # Check for audio processing tools\n",
    "    global audio_tool\n",
    "    \n",
    "    print(\"\\nChecking for audio processing tools...\")\n",
    "    if audio_tool == \"none\":\n",
    "        print(\"\\nNO AUDIO PROCESSING TOOLS FOUND\")\n",
    "        print(\"This application works best with one of these tools:\")\n",
    "        print(\"- ffmpeg (recommended): brew install ffmpeg\")\n",
    "        print(\"- libav: brew install libav\")\n",
    "        print(\"- SoX: brew install sox\")\n",
    "        \n",
    "        # Ask if user wants to continue anyway\n",
    "        response = input(\"\\nContinue anyway? Some functionality may be limited. (y/n): \")\n",
    "        if response.lower() != 'y':\n",
    "            sys.exit(1)\n",
    "    else:\n",
    "        print(f\"âœ… Found {audio_tool} for audio processing.\")\n",
    "\n",
    "# Launch the app\n",
    "if __name__ == \"__main__\":\n",
    "    setup()\n",
    "    print(\"\\ntarting Voice-to-Text Application...\")\n",
    "    print(f\"Running on {platform.processor()} with {device.upper()} acceleration\")\n",
    "    print(\"Loading models (this may take a moment)...\")\n",
    "    print(\"Once loaded, the application will be available at http://127.0.0.1:7860\")\n",
    "    demo.launch(share=False)  # Set share=True if you want a public link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26fca3d-fc47-4a61-946d-dd6411a477ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8774f5-e265-4052-9be1-3f4dc55c9a91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
